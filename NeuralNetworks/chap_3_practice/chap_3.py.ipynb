{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"modules/\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import mnist_loader\n",
    "import random\n",
    "import network2 as network_basic\n",
    "import network2_L1 as network_L1\n",
    "import network2_earlyStop as network_earlyStop\n",
    "import network2_earlyStop_modif as network_earlyStop_modif\n",
    "import network2_learningSchedule as network_learningSchedule\n",
    "import network2_momentumGradient as network_momentumGradient\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's do unregularized run\n",
    "net = network_basic.Network([784, 30, 10], cost=network_basic.CrossEntropyCost)\n",
    "unreg_run = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 0.,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see if we can outperform that with L1 (note that I'm uing network_L1 module)\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "net = network_L1.Network([784, 30, 10], cost=network_L1.CrossEntropyCost)\n",
    "\n",
    "# lmbda = 1\n",
    "L1_run_lmbda_1 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 1.,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )\n",
    "\n",
    "#lmbda = 2\n",
    "L1_run_lmbda_2 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 2.,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )\n",
    "\n",
    "#lmbda = 3\n",
    "L1_run_lmbda_3 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 3.,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's compare basic and L1\n",
    "\n",
    "L1_acc_lmbda_1 = np.asarray(L1_run_lmbda_1[1])/10000.\n",
    "L1_acc_lmbda_2 = np.asarray(L1_run_lmbda_2[1])/10000.\n",
    "L1_acc_lmbda_3 = np.asarray(L1_run_lmbda_3[1])/10000.\n",
    "unreg_acc = np.asarray(unreg_run[1])/10000.\n",
    "\n",
    "plt.plot(L1_acc_lmbda_1, color = \"red\")\n",
    "plt.plot(L1_acc_lmbda_2, color = \"green\") #the greeny is the winner\n",
    "plt.plot(L1_acc_lmbda_3, color = \"violet\")\n",
    "#plt.show()\n",
    "plt.plot(unreg_acc, color = \"black\") #baseline\n",
    "plt.show()\n",
    "\n",
    "# It seems lambda=2 is conistently better than baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The problem with derivative assigned to the Network class is that it's actually not part of the network\n",
    "# Network's behavior is dependent on cost function, which, in turn has a derivative.\n",
    "# Hence we are not able to use different cost functions without modifying the network's code. Which is not cute.\n",
    "\n",
    "# A simpler problem has to do with cross-entropy function itself. \n",
    "# network.py uses C'(sigma)* sigma'(z) formula\n",
    "# This piece of code: \n",
    "# delta = self.cost_derivative(activations[-1], y) * \\\n",
    "#     sigmoid_prime(zs[-1])\n",
    "# which, while generally true for crossentropy, shall lead to reliance on numerical internals of python \n",
    "# (very small numbers multiplied by very large numbers etc.), \n",
    "# while delta for cross-entropy has a clean analytical solution.\n",
    "# New \"cost\" class solves this problem by directly giving analytical solution to delta (for each cost function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's apply early stopping \n",
    "net = network_earlyStop.Network([784, 30, 10], cost=network_earlyStop.CrossEntropyCost)\n",
    "\n",
    "# 3 epochs stop rule\n",
    "earlyStop_run_10 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 5.,\n",
    "    early_stop_n = 10,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Why is early stopping based on maximum a bad idea?\n",
    "# The goal of early stopping is to answer a question: \"Has the network stopped consistently improving on validation?\"\n",
    "# Early stopping based on \"no-improvement in n\" answers this question by comparing two maximums: \n",
    "# 1) Maximum t-n epochs\n",
    "# 2) Maximum during last n epochs\n",
    "# These maximums are drawn from two non-independent and complex random distributions. \n",
    "# A common sense about random distributions is that the more extreme the metric we want to measure, \n",
    "# the more samples we need. In our case number of observations is number of epochs, which is rather low.\n",
    "\n",
    "# Imagine this case: during the first 7 epochs, the quality increases. Than on 8-th epochs we get a surprise maximum\n",
    "# After that, we can see growth of quality on average, but not higher than maximum. \n",
    "# Thus we shall stop the model, in suboptimal place.\n",
    "\n",
    "# A better idea seems to stop when average performance over some period becomes lower than average performance over the previous period.\n",
    "# This allows us to use more \"samples\" from over ever-changing quality distribution\n",
    "# So let's try average-by-epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's tryout our average approach\n",
    "# Let's apply early stopping \n",
    "net = network_earlyStop_modif.Network([784, 30, 10], cost=network_earlyStop_modif.CrossEntropyCost)\n",
    "\n",
    "# 3 epochs stop rule\n",
    "earlyStop_modif_run_4 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 5.,\n",
    "    early_stop_n = 5,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'll leave this part for some further experimentation (let's do other coding first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's test learning schedule\n",
    "net = network_learningSchedule.Network([784, 30, 10], cost=network_learningSchedule.CrossEntropyCost)\n",
    "\n",
    "earlyStop_modif_run_4 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 5.,\n",
    "    eta_modif_n = 10,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Why not use gradient descent on eta or lambda?\n",
    "# First things first: when searching for good hyperparameter value, that's precisely what you do.\n",
    "# Of course you do that manually, but the procedure is still the same:\n",
    "# 1) Change parameter\n",
    "# 2) See how validation quality changed.\n",
    "# 3) Guess the next best value\n",
    "\n",
    "# The problem with lambda is actually logical, not performance-based:\n",
    "# We add regularization to punish model for large weights. The best way to decrease cost\n",
    "# (given than regularization is strictly non-negative) with change in lambda is to minimize it as far as possible.\n",
    "# Mathematically it's just another derivative for fundamental equations, which is always positive, so lambda will always decrease\n",
    "# It's pretty obvious that won't help us much :) \n",
    "\n",
    "# Now for eta.\n",
    "# A simple description of eta is \"parameter that regulates how far we move based on current gradient estimation\".\n",
    "# If you look at all the cost functions, eta is not present there, as it has nothing to do with the current value\n",
    "# of cost function - only the 'travelling process\" itself.\n",
    "# Is there some other, cute way to apply gradient descent technique to eta?\n",
    "# Maybe, but limited to the scope of this exercise, I'd say nothing simple/obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What could go wrong for momentum gradient if mu > 1?\n",
    "# This would mean that each update is larger than the previous one. So we would speed up indefinetly.\n",
    "# Steps are likely to get bigger and bigger, so no happy gradient descent for you - you are likely to run far far away.\n",
    "\n",
    "# What could go wrong if mu < 0?\n",
    "# The means that every next step is decreased by previous step, whichever direction we are trying to go.\n",
    "# This would mean that cost function at every step shall try to go against each previous step.\n",
    "# Not very productive :) Moreover, we are likely to get stuck: if \"first\" step is large, and next one is small, \n",
    "# we could circle the same spot on the cost hyperplane forever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 0.658974605222\n",
      "Accuracy on training data: 46674 / 50000\n",
      "Cost on evaluation data: 1.50337854875\n",
      "Accuracy on evaluation data: 9386 / 10000\n",
      "\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 0.677066438982\n",
      "Accuracy on training data: 46982 / 50000\n",
      "Cost on evaluation data: 1.77734659878\n",
      "Accuracy on evaluation data: 9429 / 10000\n",
      "\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 0.678816373362\n",
      "Accuracy on training data: 47156 / 50000\n",
      "Cost on evaluation data: 1.91102272231\n",
      "Accuracy on evaluation data: 9464 / 10000\n",
      "\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 0.657624192624\n",
      "Accuracy on training data: 47549 / 50000\n",
      "Cost on evaluation data: 1.9744890776\n",
      "Accuracy on evaluation data: 9511 / 10000"
     ]
    }
   ],
   "source": [
    "# Let's check how momentum gradient works\n",
    "net = network_momentumGradient.Network([784, 30, 10], cost=network_momentumGradient.CrossEntropyCost)\n",
    "\n",
    "earlyStop_modif_run_4 = net.SGD(\n",
    "    training_data, 30, 10, 0.5,\n",
    "    lmbda = 5.,\n",
    "    mu = 0.7,\n",
    "    evaluation_data=validation_data,\n",
    "    monitor_evaluation_accuracy=True,\n",
    "    monitor_evaluation_cost=True,\n",
    "    monitor_training_accuracy=True,\n",
    "    monitor_training_cost=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The last exercise is theoretical, so look in theory solutions for it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
